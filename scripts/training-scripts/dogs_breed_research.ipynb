{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dogs Image Research\n",
    "\n",
    "Esse notebook foi feito para facilitar o treinamento e para gerar um report final de como foi treinado o modelo. Com ele caso seu dataset seja dividido por pastas facilita o treino.\n",
    "\n",
    "by: Crystal Silva Campos <https://github.com/campos537>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step  1\n",
    "Primeiro passo feito foi importar as bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "# Plot library\n",
    "import matplotlib.pyplot as plt\n",
    "# Fast array processing library\n",
    "import numpy as np\n",
    "# Deep Learning framework\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "# Library to find the best learning rate\n",
    "from torch_lr_finder import LRFinder\n",
    "from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step  2\n",
    "Nesse passo separamos o dataset de treino do de teste, adicionando no transforms.Compose as augmentacoes que queremos para melhorar a generalização do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test(train_data, test_data, input_size, batch_size = 64):\n",
    "#   Divide and transform the train and validation data doing augmentation if needed\n",
    "    train_transforms = transforms.Compose([\n",
    "                                        transforms.Resize(input_size),\n",
    "                                        ImageNetPolicy(),\n",
    "                                        transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.Resize(input_size),\n",
    "                                        transforms.ToTensor(),\n",
    "                                      ])\n",
    "#   Load the data depending on the path choosen  \n",
    "    train_data = datasets.ImageFolder(train_data, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(test_data, transform=test_transforms)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data,shuffle=True, batch_size=batch_size)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,shuffle=True, batch_size=batch_size)\n",
    "    return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Escolha os parametros de input que vao ser usados no dataset, tais como o input size e o tamanho do batch (Quanto maior mais memoria de video sera utilizada para o treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'test_cleaned/'\n",
    "test_data = \"test_cleaned\"\n",
    "input_size = [224,224]\n",
    "batch_size = 256\n",
    "\n",
    "trainloader, testloader = load_split_train_test(train_data,test_data, input_size, batch_size)\n",
    "print(trainloader.dataset.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Escolha a arquitetura do modelo e cheque se o CUDA esta disponivel para ser utilizado. Caso queira utilizar uma arquitetura e um modelo pretreinado pode checar o link: https://pytorch.org/docs/stable/torchvision/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checks if CUDA is available and use cpu if not\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "# Choose the model and show a summary\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "Adicione o modelo no device (CPU ou GPU) e escolha o erro a ser utilizado e Funcao Optimizadora. Alem de poder utilizar o lr_finder para escolher um bom learning rate de inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.2),\n",
    "                                  nn.Linear(512, len(trainloader.dataset.classes)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1.67E-01, momentum=0.9)\n",
    "# Assign to the device\n",
    "model.to(device)\n",
    "\n",
    "# Use learning rate finder to help choose the best one \n",
    "# lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "# lr_finder.range_test(trainloader, end_lr=100, num_iter=100)\n",
    "# lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "# lr_finder.reset() # to reset the model and optimizer to their initial state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "Escolha a quantidade de epocas que o modelo ira treinar, o nome do modelo e inicie o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "import math\n",
    "count_step = 0\n",
    "\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "best_metrics = [-999.0, 999.0]\n",
    "model_name = \"dog_breed_resnet50\"\n",
    "\n",
    "t1 = cv2.TickMeter()\n",
    "t1.start()\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "#       Save every epoch\n",
    "        if not os.path.exists('models/'+model_name+'/'):\n",
    "            os.mkdir('models/'+model_name+'/')\n",
    "        model_full_name = 'models/'+model_name+'/epoch_'+str(epoch)+'_inputsize_'+str(input_size[0])+'_'+str(input_size[1])+'_batchsize_'+str(batch_size)+'_name_'+model_name+'_.pt'\n",
    "        torch.save(model, model_full_name) # official recommended\n",
    "    \n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logps = model.forward(inputs)\n",
    "            batch_loss = criterion(logps, labels)\n",
    "            test_loss += batch_loss.item()\n",
    "\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "    val_loss_fix = round(test_loss/len(testloader),3)\n",
    "    val_acc_fix = round(accuracy/len(testloader),3)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "          f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "          f\"Validation loss: {val_loss_fix}.. \"\n",
    "          f\"Validation accuracy: {val_acc_fix}\")\n",
    "    \n",
    "    running_loss = 0\n",
    "    count_step += 1\n",
    "    model.train()\n",
    "t1.stop()\n",
    "print(\"TRAINING TIME: \", t1.getTimeSec())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7\n",
    "Ao final do treino plota a loss de treino e a de validacao para comparar e analisar como foi o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogs-env",
   "language": "python",
   "name": "dogs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
